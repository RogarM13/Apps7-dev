Problem 2, Analyzing Data:
Developing the application for the Problem 1 I already found one of the issues with the data for the adNetwork adUmbrella where the last row of the dataset contained a summary of the data. That creates a problem firstly with having a row with values that includes different info and has to be discarded in any analysis but also in the data writing process because it is not of the same format. That means it will not comply with any schema we create for the table.
For the purposes of Problem 2 I analyzed all 4 datasets given. I checked for some of the most common scenarios of corrupt/bad data. That included:
- mMissing values (especially important if the column is a primary key or an index)
- Numeric outliers (negative values where there can't be, infinite values, outliers that can't be explained e.g. values from 1-100 but one value is 152431)
- String values that do not seem to be correct (E.g. we have a string filed that we know can only be 20 characters long but we have some values that far exceed that or we have a fixed set of possible string values)
- Date data (date info that does not seem to be correct, e.g. 1970-01-01 or 2199-01-01)
The first conclusion was the issue I already found during development for Problem 1. The other problem with the data was for the datasets for adNetwork: SuperNetwork, date: 2022-09-16. There seem to be rows of data where the number of Impressions is larger than the number of Requests. Which does not seem to be possible. Other than that the only additional note I have is that the data for the tuples Date, App, Platform are duplicated in all 4 datasets. It seems like this is just the way the data is designed, t.i. not compressed into 1 row for revenue, number of requests and impressions per Date-App-Platform tuple.
In general the sanity checks depend on the data we have. The most important part is to always check that the data types are compliant (all values are of the same type within a column) and that there are no missing values in index columns. Also important is looking for outliers (weird numeric values, dates,...) and duplicates. More detailed data sanity checks require a more detailed knowledge of the data and what it represents.As a note, one of the data sanity checks that I did not include in this case (since there was not that much data) could be: Manually inspecting a random sample of the data (e.g. looking for differences between the initial 1000 rows compared to a random sample.)

Problem 3, Reliable Design
